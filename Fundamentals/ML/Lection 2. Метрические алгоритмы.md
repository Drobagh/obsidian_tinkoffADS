В задаче обучения по размеченной выборке при определении метки нового объекта x они анализируют расстояния $\rho(x,x_1),...,\rho(x,x_m)$

$\rho$ — функция расстояния или мера сходства (cos(x, z))
# Nearest Centroid Algorithm
Задача на непересекающиеся классы:  $Y = \{1,2,...,l\}, x_i \in \mathbb{R}^n$

Центроиды $$_j = \frac{1}{|i:y_i=j|}\sum_{i:y_i=j} x_i$$
$$a(x)=\arg\min_{j}\rho(x,c_j)$$
![[Pasted image 20250221133936.png]]

Особенности алгоритма:
- Обучение — вычисление центроидов,
- размер модели = (число классов) $\times$ (размер описания центроида),
- понятие центроида — любая формализация понятия «средний объект»
- подходит в задачах, где объекты разных классов распределены «колоколообразно»
# kNN
k соседей объекта x = $N(x) = \{x_1,...,x_k\} : \rho(x,x_1) \le ... \le \rho(x,x_m)$

- Классификатор
$$a(x) = mode(y_i|x_i \in N(x))$$
Определяет самую популярную метку объектов обучающей выборки, которые попали в окрестность классифицируемого объекта
![[Pasted image 20250221142553.png]]
![[Pasted image 20250222003111.png]]
Области одинаковой уверенности разделены белыми линиями - вероятности принадлежности классу 1: $\frac{i}{k}, i \in \{0,1,2,...,k\}$ = $b_1(x)$

- Регрессор
$$a(x) = mean(y_i|x_i \in N(x))$$
Усредняет метки объектов обучающей выборки, которые попали в окрестность
![[Pasted image 20250222003341.png]]
# Весовые обобщения kNN
Фундаментальный принцип ML: «более похожие объекты важнее».

Используем суперпозицию (c∘b)(x):
$b:X \rightarrow \mathbb{R}^n\ : b(x)=(b_1(x),...,b_l(x)) \in \mathbb{R}^l$
$c:\mathbb{R}^l \rightarrow \{1,2,...,l\}$
- Классификатор
$$a(x) \equiv mode(y_i|x_i \in N(x)) = \arg \max_{j} \sum_{t=1}^{k}I[y(x_t)=j]$$
$b_j(x) = \frac{\sum_{t=1}^{k}I[y(x_t)=j]}{k}$ - доля числа объектов класса j в окрестности для х
$$a(x) = \arg \max_{j} b_j(x)$$
Обобщим: $$b_j(x) = \frac{\sum_{t=1}^{k}w_t * I[y(x_t)=j]}{\sum_{t=1}^{k}w_t}$$
, где $w_1 \ge w_2 \ge ... \ge w_k \ge 0$

==Заметка== Удобней отнормировать веса, чтобы сумма была = 1

Весовые схемы
![[Pasted image 20250222020641.png]]
Kernel позволяет давать приоритет ближайшим соседям и не учитывать(занулять) дальних
![[Pasted image 20250222045027.png]]
![[Pasted image 20250222023948.png]]
Использование «более агрессивных» весовых схем (когда веса самых ближних объектов существенно превосходят остальные веса) геометрически похоже на уменьшение гиперпараметра _k_ в классическом kNN.

- Регрессия
$$b_j(x) = \frac{\sum_{t=1}^{k}w_t * y(x_t)}{\sum_{t=1}^{k}w_t}$$
![[Pasted image 20250222193518.png]]




Особенности алгоритма:
-  Работа алгоритма — вычисление и ранжирование всех расстояний
